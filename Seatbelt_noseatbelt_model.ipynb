{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db44510-b42b-44a9-8a54-418fdf810a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "044b207a-82e3-41cd-b4c0-619eb75547f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1=r\"D:\\seatbelt_Noseatbelt\"\n",
    "cate=['with_seatbelt','without_seatbelt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d103eb-6e8b-43f4-b311-56c37408a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\seatbelt_Noseatbelt\\with_seatbelt\n",
      "D:\\seatbelt_Noseatbelt\\without_seatbelt\n"
     ]
    }
   ],
   "source": [
    "for i in cate:\n",
    "    folders =os.path.join(path1, i)\n",
    "    print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49915324-676d-4585-bf36-6f4bde9e91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cate:\n",
    "    folders = os.path.join(path1, i)\n",
    "    for image in os.listdir(folders):\n",
    "        image_path =os.path.join(folders, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d7eb1b-8ecb-4b86-a885-79a915805b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 200\n",
    "path1=r\"D:\\seatbelt_Noseatbelt\"\n",
    "cate=['with_seatbelt','without_seatbelt']\n",
    "input_image =[]\n",
    "for i in cate:\n",
    "    folders = os.path.join(path1, i)\n",
    "    label =cate.index(i)\n",
    "    #j=0\n",
    "    for image in os.listdir(folders):\n",
    "        image_path =os.path.join(folders, image)\n",
    "        image_array = cv2.imread(image_path)\n",
    "        #print(image_path)\n",
    "        #print(j)\n",
    "        #j=j+1\n",
    "        image_array = cv2.resize(image_array, (image_size, image_size))\n",
    "        input_image.append([image_array, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69f1973b-44ca-411d-b960-4a8b3cac78c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9de323f6-30b6-4ed1-bbc8-1bb944f94cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "for X_values, labels in input_image:\n",
    "    X.append(X_values)\n",
    "    Y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf7688-4fa8-4c7d-9113-ed332432d19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4e5d2b-045e-478a-9521-c890d816c689",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =np.array(X)\n",
    "Y =np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ad62cf-2e61-4809-8965-8efcb8c2ccc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7756d6c-7c1e-45ad-b813-d235eb377486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20999, 200, 200, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0db15a2c-0516-42b6-8ee1-1f00144c4d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11660+9339 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beebf356-bda7-49e8-8b91-5c590fff47f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20999-12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a22310e-9de3-4608-a1df-0d8e324efaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12999"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8999+4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7fe26bf-5bc3-4065-927e-287f9bd3ba95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16799.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20999*.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7292ae7-20cc-4f6f-b33b-79e86717133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X[0:5999]  \n",
    "x_test = X[5999:9999]\n",
    "\n",
    "y_train = Y[0:5999]   \n",
    "y_test = Y[5999:9999] \n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "956a020f-2c4c-4ce7-bf23-85d714cd2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X =X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dadf20b7-9a78-420b-b38a-34e0f130a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train/255  # Now in range [0, 1] Pixel intensity values fall within the range [0.0, 1.0].\n",
    "x_test=x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1054901-c185-4351-bd55-11eb416accb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59e961dc-e601-47c8-ad04-16c8001f9fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kalyani Patil\\AppData\\Local\\Temp\\ipykernel_3144\\1216720578.py:7: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(input_shape=X.shape[1:], include_top=False, weights='imagenet')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "# Load MobileNetV2 as the base model (without top layers)\n",
    "base_model = MobileNetV2(input_shape=X.shape[1:], include_top=False, weights='imagenet')\n",
    "\n",
    "# Freeze base model weights (so pretrained features remain unchanged)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Replaces Flatten() for better efficiency\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)  # Regularization\n",
    "output = Dense(2, activation='softmax')(x)  # 2 classes: Seatbelt / No Seatbelt\n",
    "\n",
    "# Define the final model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcf9ed0c-e353-4774-98e6-8a60f1de0c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f02e1345-6386-499d-a9b1-e5f77ae7670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer =adam, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f66532a9-4972-4351-81e6-952d5a7760ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5999, 200, 200, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d385aed-e1f2-4a9a-be5e-03d1b5ed9f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5999,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7eab66c-96ae-4d13-9e91-aa214530d682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 554ms/step - accuracy: 0.7509 - loss: 0.5033 - val_accuracy: 0.8775 - val_loss: 0.2794\n",
      "Epoch 2/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 529ms/step - accuracy: 0.8895 - loss: 0.2475 - val_accuracy: 0.9108 - val_loss: 0.2084\n",
      "Epoch 3/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 553ms/step - accuracy: 0.9292 - loss: 0.1796 - val_accuracy: 0.9242 - val_loss: 0.1760\n",
      "Epoch 4/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 538ms/step - accuracy: 0.9461 - loss: 0.1392 - val_accuracy: 0.9300 - val_loss: 0.1685\n",
      "Epoch 5/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 527ms/step - accuracy: 0.9588 - loss: 0.1096 - val_accuracy: 0.9425 - val_loss: 0.1524\n",
      "Epoch 6/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 539ms/step - accuracy: 0.9619 - loss: 0.0978 - val_accuracy: 0.9508 - val_loss: 0.1471\n",
      "Epoch 7/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 538ms/step - accuracy: 0.9718 - loss: 0.0748 - val_accuracy: 0.9233 - val_loss: 0.1933\n",
      "Epoch 8/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 543ms/step - accuracy: 0.9739 - loss: 0.0705 - val_accuracy: 0.9400 - val_loss: 0.1724\n",
      "Epoch 9/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 536ms/step - accuracy: 0.9844 - loss: 0.0495 - val_accuracy: 0.9517 - val_loss: 0.1293\n",
      "Epoch 10/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 530ms/step - accuracy: 0.9849 - loss: 0.0424 - val_accuracy: 0.9517 - val_loss: 0.1598\n",
      "Epoch 11/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 533ms/step - accuracy: 0.9845 - loss: 0.0453 - val_accuracy: 0.9350 - val_loss: 0.2033\n",
      "Epoch 12/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 533ms/step - accuracy: 0.9883 - loss: 0.0329 - val_accuracy: 0.9508 - val_loss: 0.1413\n",
      "Epoch 13/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 541ms/step - accuracy: 0.9907 - loss: 0.0288 - val_accuracy: 0.9483 - val_loss: 0.1387\n",
      "Epoch 14/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 528ms/step - accuracy: 0.9876 - loss: 0.0344 - val_accuracy: 0.9492 - val_loss: 0.1632\n",
      "Epoch 15/15\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 577ms/step - accuracy: 0.9907 - loss: 0.0274 - val_accuracy: 0.9442 - val_loss: 0.1678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x245149a78f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=15,validation_split=.2,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "784a321b-60bd-4023-b3a7-53ed73378e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 403ms/step\n",
      "Confusion Matrix:\n",
      "[[2135  121]\n",
      " [  78 1666]]\n",
      "------------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      2256\n",
      "           1       0.93      0.96      0.94      1744\n",
      "\n",
      "    accuracy                           0.95      4000\n",
      "   macro avg       0.95      0.95      0.95      4000\n",
      "weighted avg       0.95      0.95      0.95      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred_classes = pred.argmax(axis=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "tab = confusion_matrix(y_test, pred_classes)\n",
    "print('Confusion Matrix:')\n",
    "print(tab)\n",
    "print('------------------------------------------------------')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "323372ec-a303-4f49-9b65-4d3babb3a6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"seatbelt_noseatbelt_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616905f-0298-4121-98d0-399e829bde73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
